{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑斯蒂回归 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二项逻辑斯蒂回归 适用问题：二分类\n",
    "\n",
    "多项逻辑斯蒂回归 适用问题：多分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二分类\n",
    "# 优化方法使用随机梯度\n",
    "class Logistic_Regression(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.learning_step = 0.0001 # 学习率\n",
    "        self.max_iteration = 5000 # 分类正确上界，当分类正确的次数超过上界时，认为已训练好，退出训练\n",
    "\n",
    "    def train(self,features, labels):\n",
    "        self.w = [0.0] * (len(features[0]) + 1) # 初始化模型参数 某位元素为偏移b\n",
    "\n",
    "        correct_count = 0 # 分类正确的次数\n",
    "\n",
    "        while correct_count < self.max_iteration:\n",
    "\n",
    "            # 随机选取数据(xi,yi)\n",
    "            index = random.randint(0, len(labels) - 1)\n",
    "            x = list(features[index])\n",
    "            x.append(1.0)\n",
    "            y = labels[index]\n",
    "\n",
    "            if y == self.predict_(x): # 分类正确的次数加1,并跳过下面的步骤\n",
    "                correct_count += 1\n",
    "                continue\n",
    "\n",
    "            wx = sum([self.w[i] * x[i] for i in range(len(self.w))])\n",
    "            while wx>700: # 控制运算结果越界\n",
    "                wx/=2\n",
    "            exp_wx = math.exp(wx)\n",
    "\n",
    "            for i in range(len(self.w)):\n",
    "                self.w[i] -= self.learning_step * \\\n",
    "                    (-y * x[i] + float(x[i] * exp_wx) / float(1 + exp_wx)) # 梯度上升\n",
    "\n",
    "    def predict_(self,x):\n",
    "        wx = sum([self.w[j] * x[j] for j in range(len(self.w))])\n",
    "        while wx>700: # 控制运算结果越界\n",
    "            wx/=2\n",
    "        exp_wx = math.exp(wx)\n",
    "\n",
    "        predict1 = exp_wx / (1 + exp_wx)\n",
    "        predict0 = 1 / (1 + exp_wx)\n",
    "\n",
    "        if predict1 > predict0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    def predict(self,features):\n",
    "        labels = []\n",
    "\n",
    "        for feature in features:\n",
    "            x = list(feature)\n",
    "            x.append(1)\n",
    "            labels.append(self.predict_(x))\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start read data...\n",
      "read data cost 9.078089 seconds\n",
      "Start training...\n",
      "training cost 1.878779 seconds\n",
      "Start predicting...\n",
      "predicting cost 3.242741 seconds\n",
      "The accruacy score is 0.976118\n"
     ]
    }
   ],
   "source": [
    "print(\"Start read data...\")\n",
    "\n",
    "time_1 = time.time()\n",
    "\n",
    "raw_data = pd.read_csv('../data/train_binary.csv', header=0)  # 读取csv数据，并将第一行视为表头，返回DataFrame类型\n",
    "data = raw_data.values\n",
    "\n",
    "features = data[::, 1::]\n",
    "labels = data[::, 0]\n",
    "\n",
    "# 避免过拟合，采用交叉验证，随机选取33%数据作为测试集，剩余为训练集\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=0)\n",
    "\n",
    "time_2 = time.time()\n",
    "print('read data cost %f seconds' % (time_2 - time_1))\n",
    "\n",
    "print('Start training...')\n",
    "lr = Logistic_Regression()\n",
    "lr.train(train_features, train_labels)\n",
    "time_3 = time.time()\n",
    "print('training cost %f seconds' % (time_3 - time_2))\n",
    "\n",
    "print('Start predicting...')\n",
    "test_predict = lr.predict(test_features)\n",
    "time_4 = time.time()\n",
    "print('predicting cost %f seconds' % (time_4 - time_3))\n",
    "\n",
    "score = accuracy_score(test_labels, test_predict)\n",
    "print(\"The accruacy score is %f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sk-learn实现LR进行多分类\n",
    "### sklearn.linear_model.LogisticRegression\n",
    "\n",
    "solver参数决定了我们对逻辑回归损失函数的优化方法，有四种算法可以选择，分别是：\n",
    "- a) liblinear：使用了开源的liblinear库实现，内部使用了坐标轴下降法来迭代优化损失函数。\n",
    "- b) lbfgs：拟牛顿法的一种，利用损失函数二阶导数矩阵即海森矩阵来迭代优化损失函数。\n",
    "- c) newton-cg：也是牛顿法家族的一种，利用损失函数二阶导数矩阵即海森矩阵来迭代优化损失函数。\n",
    "- d) sag：即随机平均梯度下降，是梯度下降法的变种，和普通梯度下降法的区别是每次迭代仅仅用一部分的样本来计算梯度，适合于样本数据多的时候。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start read data...\n",
      "read data cost 9.120260 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Start read data...\")\n",
    "time_1 = time.time()\n",
    "\n",
    "raw_data = pd.read_csv('../data/train.csv', header=0) \n",
    "data = raw_data.values\n",
    "\n",
    "features = data[::, 1::]\n",
    "labels = data[::, 0]\n",
    "\n",
    "# 随机选取33%数据作为测试集，剩余为训练集\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=0)\n",
    "\n",
    "time_2 = time.time()\n",
    "print('read data cost %f seconds' % (time_2 - time_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    }
   ],
   "source": [
    "print('Start training...') \n",
    "# multi_class可选‘ovr’, ‘multinomial’，默认为ovr用于二类分类，multinomial用于多类分类\n",
    "clf = LogisticRegression(max_iter=100,solver='saga',multi_class='multinomial')\n",
    "clf.fit(train_features,train_labels)\n",
    "time_3 = time.time()\n",
    "print('training cost %f seconds' % (time_3 - time_2))\n",
    "\n",
    "print('Start predicting...')\n",
    "test_predict = clf.predict(test_features)\n",
    "time_4 = time.time()\n",
    "print('predicting cost %f seconds' % (time_4 - time_3))\n",
    "\n",
    "\n",
    "score = accuracy_score(test_labels, test_predict)\n",
    "print(\"The accruacy score is %f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
