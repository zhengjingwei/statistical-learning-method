{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ID3（基于信息增益）\n",
    "- C4.5（基于信息增益比）\n",
    "- CART（gini指数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### entropy：$H(x) = -\\sum_{i=1}^{n}p_i\\log{p_i}$\n",
    "\n",
    "#### conditional entropy: $H(X|Y)=\\sum{P(X|Y)}\\log{P(X|Y)}$\n",
    "\n",
    "#### information gain : $g(D, A)=H(D)-H(D|A)$\n",
    "\n",
    "#### information gain ratio: $g_R(D, A) = \\frac{g(D,A)}{H(A)}$\n",
    "\n",
    "#### gini index:$Gini(D)=\\sum_{k=1}^{K}p_k\\log{p_k}=1-\\sum_{k=1}^{K}p_k^2$\n",
    "\n",
    "其中特征A对数据集D的经验条件熵$H(D|A)$\n",
    "\n",
    "$$H(D|A)=\\sum_{i=1}^{n}\\frac{|D_i|}{|D|}H(D_i)\\sum_{k=1}^{K}\\log{\\frac{|D_{ik}|}{|D_i|}}$$\n",
    "\n",
    "$D_i$表示根据特征A的取值将D划分为n个子集$D_1,D_2,...,D_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "import math\n",
    "from math import log\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 书上例5.1\n",
    "def create_data():\n",
    "    datasets = [['青年', '否', '否', '一般', '否'],\n",
    "               ['青年', '否', '否', '好', '否'],\n",
    "               ['青年', '是', '否', '好', '是'],\n",
    "               ['青年', '是', '是', '一般', '是'],\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '好', '否'],\n",
    "               ['中年', '是', '是', '好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '好', '是'],\n",
    "               ['老年', '是', '否', '好', '是'],\n",
    "               ['老年', '是', '否', '非常好', '是'],\n",
    "               ['老年', '否', '否', '一般', '否'],\n",
    "               ]\n",
    "    labels = [u'年龄', u'有工作', u'有自己的房子', u'信贷情况', u'类别']\n",
    "    # 返回数据集和每个维度的名称\n",
    "    return datasets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, labels = create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(datasets, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 熵 H(D)\n",
    "def cal_ent(datasets):\n",
    "    n = len(datasets)\n",
    "    label_count = {}\n",
    "    for i in range(n):\n",
    "        label = datasets[i][-1]\n",
    "        if label in label_count:\n",
    "            label_count[label] +=1\n",
    "        else:\n",
    "            label_count[label] = 1\n",
    "    ent = - sum( [(c/n * log(c/n,2)) for c in label_count.values()] ) \n",
    "    return ent\n",
    "\n",
    "# 经验条件熵 H(D|A) 第axis个特征\n",
    "def cal_cond_ent(datasets ,axis=0):\n",
    "    n = len(datasets)\n",
    "    feature_count = {}\n",
    "    ent = 0\n",
    "    for i in range(n):\n",
    "        if datasets[i][axis] in feature_count:\n",
    "            feature_count[datasets[i][axis]] +=1\n",
    "        else:\n",
    "            feature_count[datasets[i][axis]] = 1\n",
    "    for d in feature_count:\n",
    "        ent += feature_count[d]/n * cal_ent([p for p in datasets if p[axis] == d]) \n",
    "    return ent\n",
    "\n",
    "# 信息增益\n",
    "def info_gain(datasets):\n",
    "    features = datasets.shape[1] -1\n",
    "    info_gains = []\n",
    "    ent = cal_ent(datasets)\n",
    "    for i in range(features):\n",
    "        info_gains.append((i, ent - cal_cond_ent(datasets,i)))\n",
    "    for i in range(features):\n",
    "        print('特征:{0} info_gain = {1:.3f}'.format(labels[i],info_gains[i][-1]))\n",
    "    \n",
    "    best = max(info_gains, key= lambda x:x[-1])\n",
    "    print('最优特征:{}'.format(labels[best[0]]))\n",
    "    return info_gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array(train_data)\n",
    "info_gain(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义节点类 二叉树\n",
    "class Node:\n",
    "    def __init__(self, leaf=True, label=None,feature=None):\n",
    "        self.leaf = leaf       # 是否为叶子节点\n",
    "        self.label = label     # 叶节点的label；若是内部节点，则为none\n",
    "        self.feature = feature # 该节点的特征Ag\n",
    "        self.tree = {}         # Ag每个可能的值构成\n",
    "        self.result = {'label:': self.label, 'feature': self.feature, 'tree': self.tree}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}'.format(self.result)\n",
    "\n",
    "    def add_node(self, val, node):\n",
    "        self.tree[val] = node #添加特征Ag取值为val的节点\n",
    "\n",
    "    def predict(self, features):\n",
    "        if self.leaf is True:\n",
    "            return self.label\n",
    "        return self.tree[features[self.feature]].predict(features) # 访问子树, features[self.feature]表示测试用例在该节点特征的取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3_DTree:\n",
    "    def __init__(self,epsilon=0.1):\n",
    "        self.tree = {}\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}'.format(self.result)\n",
    "\n",
    "    # 熵 H(D)\n",
    "    def cal_ent(self, datasets):\n",
    "        n = len(datasets)\n",
    "        label_count = {}\n",
    "        for i in range(n):\n",
    "            label = datasets[i][-1]\n",
    "            if label in label_count:\n",
    "                label_count[label] +=1\n",
    "            else:\n",
    "                label_count[label] = 1\n",
    "        ent = - sum( [(c/n * log(c/n,2)) for c in label_count.values()] ) \n",
    "        return ent\n",
    "    \n",
    "    # 经验条件熵 H(D|A) 第axis个特征\n",
    "    def cal_cond_ent(self, datasets ,axis=0):\n",
    "        n = len(datasets)\n",
    "        feature_count = {}\n",
    "        cond_ent = 0\n",
    "        for i in range(n):\n",
    "            if datasets[i][axis] in feature_count:\n",
    "                feature_count[datasets[i][axis]] +=1\n",
    "            else:\n",
    "                feature_count[datasets[i][axis]] = 1\n",
    "        for d in feature_count:\n",
    "            cond_ent += feature_count[d]/n * cal_ent([p for p in datasets if p[axis] == d]) \n",
    "        return cond_ent\n",
    "    \n",
    "    def info_gain(self, ent, con_ent):\n",
    "        return ent - con_ent\n",
    "    \n",
    "    # 信息增益\n",
    "    def cal_info_gain(self, datasets):\n",
    "        features = len(datasets[0]) -1\n",
    "        info_gains = []\n",
    "        ent = cal_ent(datasets)\n",
    "        for i in range(features):\n",
    "            info_gains.append((i, ent - cal_cond_ent(datasets,axis=i))) #第i个特征\n",
    "        \n",
    "        best = max(info_gains, key= lambda x:x[-1])\n",
    "        return best #（axis， info_gain)\n",
    "    \n",
    "    def train(self, datasets,features):\n",
    "        y_train = datasets[:,-1]\n",
    "        y_set = set(y_train)\n",
    "        \n",
    "        # (1)如果所有实例属于同一类别Ck\n",
    "        if len(y_set) == 1:\n",
    "            return Node(leaf=True, label=y_set.pop(), feature=None) \n",
    "\n",
    "        # (2)如果特征集合为空\n",
    "        label_count = {}\n",
    "        for i in y_train:\n",
    "            if i not in label_count:\n",
    "                label_count[i] = 1\n",
    "            else:\n",
    "                label_count[i] +=1\n",
    "        max_class = max(label_count, key=lambda x:x[-1])[0] # 实例最多的类\n",
    "\n",
    "        if len(features) == 0:\n",
    "            return Node(leaf=True, label=max_class)\n",
    "        \n",
    "        # (3)计算信息增益，选择信息增益最大特征Ag\n",
    "        max_feature, max_gain = self.cal_info_gain(datasets)\n",
    "        \n",
    "        # (4)如果Ag的信息增益小于阈值eta,则置T为单节点树，并将D中是实例数最大的类Ck作为该节点的类标记，返回T\n",
    "        if max_gain < self.epsilon:\n",
    "            return Node(leaf=True, label=max_class)\n",
    "        \n",
    "        # (5)构建树\n",
    "        node_tree = Node(leaf=False,feature=max_feature)\n",
    "        sub_features = list(filter(lambda x:x!=max_feature, features)) # 剩余特征集 {A-Ag}\n",
    "        max_feature_data = datasets[:,max_feature]                      # 信息增益最大的特征对应列\n",
    "        feature_value_list = list(set(max_feature_data))                # 保存信息增益最大的特征可能的取值 \n",
    "        \n",
    "        # 根据Ag=ai将D划分为子集Di\n",
    "        for f in feature_value_list:\n",
    "            index = []\n",
    "            for i in range(len(datasets)):\n",
    "                if datasets[i][max_feature] == f: \n",
    "                    index.append(i) # Di所在的行\n",
    "            sub_data = datasets[index]\n",
    "            sub_tree = self.train(sub_data,features) # 递归生成子树\n",
    "            node_tree.add_node(f, sub_tree)        \n",
    "        \n",
    "        return node_tree\n",
    "                   \n",
    "              \n",
    "    def fit(self,datasets):\n",
    "        self.tree = self.train(datasets,list(range(len(datasets[0])-1))) # feature为特征序号列表\n",
    "        return self.tree\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return self.tree.predict(X_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(train_data)\n",
    "dt = ID3_DTree()\n",
    "tree = dt.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [u'年龄', u'有工作', u'有自己的房子', u'信贷情况', u'类别']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.predict(['老年', '否', '否', '一般'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
